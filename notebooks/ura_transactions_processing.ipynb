{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_list = [\n",
    "    \"URA_ResidentialTransaction_EC2020_20240917220317\",\n",
    "    \"URA_ResidentialTransaction_EC2021_20240917220358\",\n",
    "    \"URA_ResidentialTransaction_EC2022_20240917220420\",\n",
    "    \"URA_ResidentialTransaction_EC2023_20240917220459\",\n",
    "    \"URA_ResidentialTransaction_EC2024_20240917220523\",\n",
    "]\n",
    "\n",
    "condo_list = [\n",
    "    \"URA_ResidentialTransaction_Conda2020_20240917220234\",\n",
    "    \"URA_ResidentialTransaction_Conda2021_20240917220149\",\n",
    "    \"URA_ResidentialTransaction_Conda2022_20240917220116\",\n",
    "    \"URA_ResidentialTransaction_Conda2023_20240917215948\",\n",
    "    \"URA_ResidentialTransaction_Condo2024_20240917215852\",\n",
    "]\n",
    "\n",
    "hdb_list = [\n",
    "    \"ResaleFlatPricesBasedonRegistrationDateFromJan2015toDec2016\",\n",
    "    \"ResaleflatpricesbasedonregistrationdatefromJan2017onwards\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_df = [pd.read_csv(f\"../data/raw_data/csv/ura/{ec}.csv\") for ec in ec_list]\n",
    "ec_df = pd.concat(ec_df)\n",
    "ec_df.to_parquet(r\"../data/L1/housing_ec_transaction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "condo_df = [\n",
    "    pd.read_csv(f\"../data/raw_data/csv/ura/{condo}.csv\") for condo in condo_list\n",
    "]\n",
    "condo_df = pd.concat(condo_df)\n",
    "condo_df['Area (SQM)'] = condo_df['Area (SQM)'].str.replace(',', '').str.strip()\n",
    "condo_df['Area (SQM)'] = pd.to_numeric(condo_df['Area (SQM)'], errors='coerce')\n",
    "condo_df.to_parquet(r\"../data/L1/housing_condo_transaction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_df = [pd.read_csv(f\"../data/raw_data/csv/datagov/{hdb}.csv\") for hdb in hdb_list]\n",
    "hdb_df = pd.concat(hdb_df)\n",
    "\n",
    "import re\n",
    "\n",
    "def standardize_lease_duration(lease):\n",
    "    if isinstance(lease, int) or lease.isdigit():\n",
    "        return int(lease) * 12  # assume months\n",
    "    else:\n",
    "        match = re.match(r'(\\d+) years?\\s*', lease) #(\\d+) months?\n",
    "        if match:\n",
    "            years = int(match.group(1))\n",
    "            # months = int(match.group(2)) if match.group(2) else 0\n",
    "            return years * 12 #+ months\n",
    "        else:\n",
    "            return None  # or raise an exception\n",
    "\n",
    "hdb_df['remaining_lease_months'] = hdb_df['remaining_lease'].apply(standardize_lease_duration)\n",
    "hdb_df.drop('remaining_lease', axis=1, inplace=True)\n",
    "hdb_df.to_parquet(r\"../data/L1/housing_hdb_transaction.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining to idenfity all unique condo and flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.concat(\n",
    "    [\n",
    "        condo_df[[\"Project Name\", \"Street Name\"]].drop_duplicates(),\n",
    "        ec_df[[\"Project Name\", \"Street Name\"]].drop_duplicates(),\n",
    "        hdb_df[[\"block\", \"street_name\"]].drop_duplicates(),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "NameAddress_list = [\"Project Name\", \"Street Name\", \"block\", \"street_name\"]\n",
    "for i in NameAddress_list:\n",
    "    housing_df[i] = housing_df[i].fillna(\"\")\n",
    "housing_df[\"NameAddress\"] = housing_df[NameAddress_list].agg(\" \".join, axis=1)\n",
    "housing_df[\"NameAddress\"] = [i.strip() for i in housing_df[\"NameAddress\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFFINITY AT SERANGOON SERANGOON NORTH AVENUE 1\n",
      "THE FLORENCE RESIDENCES HOUGANG AVENUE 2\n",
      "THE GARDEN RESIDENCES SERANGOON NORTH VIEW\n",
      "THE PROMENADE@PELIKAT JALAN PELIKAT\n",
      "PRIMO RESIDENCES JALAN PELIKAT\n",
      "SENGKANG GRAND RESIDENCES COMPASSVALE BOW\n",
      "COMPASS HEIGHTS SENGKANG SQUARE\n",
      "A TREASURE TROVE PUNGGOL WALK\n",
      "BOTANIQUE AT BARTLEY UPPER PAYA LEBAR ROAD\n",
      "REGENTVILLE HOUGANG STREET 92\n"
     ]
    }
   ],
   "source": [
    "for search_string in housing_df['NameAddress'][:10]:\n",
    "    print(search_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneMap Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "url = \"https://www.onemap.gov.sg/api/auth/post/getToken\"\n",
    "      \n",
    "payload = {\n",
    "        \"email\": os.environ['ONEMAP_EMAIL'],\n",
    "        \"password\": os.environ['ONEMAP_EMAIL_PASSWORD']\n",
    "      }\n",
    "      \n",
    "response = requests.request(\"POST\", url, json=payload)\n",
    "access_token = json.loads(response.text)['access_token']\n",
    "headers = {\"Authorization\": f\"{access_token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for X, Y and other data on OneMap\n",
    "- this will take a while\n",
    "- with exponential backoff and limit to failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "df_list = []\n",
    "max_retries = 3\n",
    "initial_backoff = 1  # seconds\n",
    "max_backoff = 32  # seconds\n",
    "\n",
    "for search_string in housing_df['NameAddress']:\n",
    "    retries = 0\n",
    "    success = False\n",
    "    backoff = initial_backoff\n",
    "\n",
    "    while not success and retries < max_retries:\n",
    "        try:\n",
    "            url = f\"https://www.onemap.gov.sg/api/common/elastic/search?searchVal={search_string}&returnGeom=Y&getAddrDetails=Y&pageNum=1\"\n",
    "            response = requests.request(\"GET\", url, headers=headers)\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "            _df = pd.DataFrame(json.loads(response.text)['results']).reset_index().rename({'index':'search_result'}, axis=1)\n",
    "            _df['NameAddress'] = search_string\n",
    "            df_list.append(_df)\n",
    "\n",
    "            success = True\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            retries += 1\n",
    "            backoff = min(backoff * 2, max_backoff)  # Exponential backoff\n",
    "            delay = backoff + random.uniform(0, 1)  # Add some jitter to the delay\n",
    "            print(f\"Request failed for {search_string}. Retrying in {delay:.2f} seconds. (Retry {retries}/{max_retries})\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "    if not success:\n",
    "        print(f\"Failed to retrieve data for {search_string} after {max_retries} retries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_searched = pd.concat(df_list)\n",
    "df_housing_searched.to_parquet(r\"../data/L1/housing_unique_searched.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
