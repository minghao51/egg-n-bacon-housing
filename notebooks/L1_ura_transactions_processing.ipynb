{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# procesing all housing with additional latlon and discard extra info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_list = [\n",
    "    \"URA_ResidentialTransaction_EC2020_20240917220317\",\n",
    "    \"URA_ResidentialTransaction_EC2021_20240917220358\",\n",
    "    \"URA_ResidentialTransaction_EC2022_20240917220420\",\n",
    "    \"URA_ResidentialTransaction_EC2023_20240917220459\",\n",
    "    \"URA_ResidentialTransaction_EC2024_20240917220523\",\n",
    "]\n",
    "\n",
    "condo_list = [\n",
    "    \"URA_ResidentialTransaction_Conda2020_20240917220234\",\n",
    "    \"URA_ResidentialTransaction_Conda2021_20240917220149\",\n",
    "    \"URA_ResidentialTransaction_Conda2022_20240917220116\",\n",
    "    \"URA_ResidentialTransaction_Conda2023_20240917215948\",\n",
    "    \"URA_ResidentialTransaction_Condo2024_20240917215852\",\n",
    "]\n",
    "\n",
    "hdb_list = [\n",
    "    \"ResaleFlatPricesBasedonRegistrationDateFromJan2015toDec2016\",\n",
    "    \"ResaleflatpricesbasedonregistrationdatefromJan2017onwards\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_df = [pd.read_csv(f\"../data/raw_data/csv/ura/{ec}.csv\") for ec in ec_list]\n",
    "ec_df = pd.concat(ec_df)\n",
    "ec_df.to_parquet(r\"../data/L1/housing_ec_transaction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "condo_df = [\n",
    "    pd.read_csv(f\"../data/raw_data/csv/ura/{condo}.csv\") for condo in condo_list\n",
    "]\n",
    "condo_df = pd.concat(condo_df)\n",
    "condo_df['Area (SQM)'] = condo_df['Area (SQM)'].str.replace(\n",
    "    ',', '').str.strip()\n",
    "condo_df['Area (SQM)'] = pd.to_numeric(condo_df['Area (SQM)'], errors='coerce')\n",
    "condo_df.to_parquet(r\"../data/L1/housing_condo_transaction.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hdb_df = [pd.read_csv(f\"../data/raw_data/csv/datagov/{hdb}.csv\")\n",
    "          for hdb in hdb_list]\n",
    "hdb_df = pd.concat(hdb_df)\n",
    "\n",
    "\n",
    "def standardize_lease_duration(lease):\n",
    "    if isinstance(lease, int) or lease.isdigit():\n",
    "        return int(lease) * 12  # assume months\n",
    "    else:\n",
    "        match = re.match(r'(\\d+) years?\\s*', lease)  # (\\d+) months?\n",
    "        if match:\n",
    "            years = int(match.group(1))\n",
    "            # months = int(match.group(2)) if match.group(2) else 0\n",
    "            return years * 12  # + months\n",
    "        else:\n",
    "            return None  # or raise an exception\n",
    "\n",
    "\n",
    "hdb_df['remaining_lease_months'] = hdb_df['remaining_lease'].apply(\n",
    "    standardize_lease_duration)\n",
    "hdb_df.drop('remaining_lease', axis=1, inplace=True)\n",
    "hdb_df.to_parquet(r\"../data/L1/housing_hdb_transaction.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining to idenfity all unique condo and flats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "condo_df['property_type'] = 'private'\n",
    "ec_df['property_type'] = 'private'\n",
    "hdb_df['property_type'] = 'hdb'\n",
    "\n",
    "\n",
    "housing_df = pd.concat(\n",
    "    [\n",
    "        condo_df[[\"Project Name\", \"Street Name\",\n",
    "                  \"property_type\"]].drop_duplicates(),\n",
    "        ec_df[[\"Project Name\", \"Street Name\", 'property_type']].drop_duplicates(),\n",
    "        hdb_df[[\"block\", \"street_name\", 'property_type']].drop_duplicates(),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "NameAddress_list = [\"Project Name\", \"Street Name\",\n",
    "                    \"block\", \"street_name\", \"property_type\"]\n",
    "for i in NameAddress_list:\n",
    "    housing_df[i] = housing_df[i].fillna(\"\")\n",
    "housing_df[\"NameAddress\"] = housing_df[NameAddress_list].agg(\" \".join, axis=1)\n",
    "housing_df[\"NameAddress\"] = [i.strip() for i in housing_df[\"NameAddress\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFFINITY AT SERANGOON SERANGOON NORTH AVENUE 1   private\n",
      "THE FLORENCE RESIDENCES HOUGANG AVENUE 2   private\n",
      "THE GARDEN RESIDENCES SERANGOON NORTH VIEW   private\n",
      "THE PROMENADE@PELIKAT JALAN PELIKAT   private\n",
      "PRIMO RESIDENCES JALAN PELIKAT   private\n",
      "SENGKANG GRAND RESIDENCES COMPASSVALE BOW   private\n",
      "COMPASS HEIGHTS SENGKANG SQUARE   private\n",
      "A TREASURE TROVE PUNGGOL WALK   private\n",
      "BOTANIQUE AT BARTLEY UPPER PAYA LEBAR ROAD   private\n",
      "REGENTVILLE HOUGANG STREET 92   private\n"
     ]
    }
   ],
   "source": [
    "for search_string in housing_df['NameAddress'][:10]:\n",
    "    print(search_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneMap Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "url = \"https://www.onemap.gov.sg/api/auth/post/getToken\"\n",
    "\n",
    "payload = {\n",
    "    \"email\": os.environ['ONEMAP_EMAIL'],\n",
    "    \"password\": os.environ['ONEMAP_EMAIL_PASSWORD']\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload)\n",
    "access_token = json.loads(response.text)['access_token']\n",
    "headers = {\"Authorization\": f\"{access_token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for X, Y and other data on OneMap\n",
    "- this will take a while\n",
    "- with exponential backoff and limit to failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "df_list = []\n",
    "max_retries = 3\n",
    "initial_backoff = 1  # seconds\n",
    "max_backoff = 32  # seconds\n",
    "\n",
    "for search_string in housing_df['NameAddress']:\n",
    "    retries = 0\n",
    "    success = False\n",
    "    backoff = initial_backoff\n",
    "\n",
    "    while not success and retries < max_retries:\n",
    "        try:\n",
    "            url = f\"https://www.onemap.gov.sg/api/common/elastic/search?searchVal={search_string}&returnGeom=Y&getAddrDetails=Y&pageNum=1\"\n",
    "            response = requests.request(\"GET\", url, headers=headers)\n",
    "            response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "            _df = pd.DataFrame(json.loads(response.text)['results']).reset_index().rename(\n",
    "                {'index': 'search_result'}, axis=1)\n",
    "            _df['NameAddress'] = search_string\n",
    "            df_list.append(_df)\n",
    "\n",
    "            success = True\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            retries += 1\n",
    "            backoff = min(backoff * 2, max_backoff)  # Exponential backoff\n",
    "            # Add some jitter to the delay\n",
    "            delay = backoff + random.uniform(0, 1)\n",
    "            print(\n",
    "                f\"Request failed for {search_string}. Retrying in {delay:.2f} seconds. (Retry {retries}/{max_retries})\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "    if not success:\n",
    "        print(\n",
    "            f\"Failed to retrieve data for {search_string} after {max_retries} retries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing_searched = pd.concat(df_list)\n",
    "df_housing_searched.to_parquet(r\"../data/L2/housing_unique_searched.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
